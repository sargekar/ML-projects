# Install necessary packages
!pip install pyspark boto

# Import boto3 for accessing AWS S3 and other necessary libraries
import boto3

# Define AWS credentials for accessing the S3 bucket
aws_access_key_id = '########'
aws_secret_access_key = '########'

# Create a session using the AWS credentials
session = boto3.Session(
    aws_access_key_id=aws_access_key_id,
    aws_secret_access_key=aws_secret_access_key
)

# Create S3 resource object from the session
s3 = session.resource('s3')

# Access the S3 bucket named 'spamemail'
bucket = s3.Bucket('spamemail')

# List all objects in the 'spamemail' S3 bucket and print their keys (names)
for obj in bucket.objects.all():
    print(obj.key)

# Import StringIO to handle the file data in-memory
from io import StringIO

# Set up S3 client to download data from the bucket
s3 = boto3.client('s3', aws_access_key_id='########', aws_secret_access_key='######')

# Define the S3 bucket and the file key (path) for the dataset
bucket_name = 'spamemail'
file_key = 'spambase.data'

# Fetch the object from the bucket using the client and read the content
obj = s3.get_object(Bucket=bucket_name, Key=file_key)
data = obj['Body'].read().decode('utf-8')

# Load the CSV data into a pandas DataFrame and set column names
df_1 = pd.read_csv(StringIO(data), delimiter=',', names=[f"feature_{i}" for i in range(57)] + ["label"])

# Print the first few rows and columns of the pandas DataFrame to check
print(df.head())
print(df.columns)

# Install the PySpark and nltk libraries
!pip install pyspark
!pip install nltk

# Import necessary libraries for data manipulation and machine learning
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pyspark.sql.types import StructType, StructField, DoubleType, IntegerType
from pyspark.ml.feature import VectorAssembler, StandardScaler
from pyspark.ml.classification import NaiveBayes
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from pyspark.ml import Pipeline

# Import SparkSession from PySpark
from pyspark.sql import SparkSession

# Start a Spark session for PySpark to work with
spark = SparkSession.builder \
    .master("local") \
    .appName("SpamBayes") \
    .getOrCreate()

# Define the schema for the DataFrame, including 57 features and the label
schema = StructType([
    *([StructField(f"feature_{i}", DoubleType(), True) for i in range(57)]) +
    [StructField("label", IntegerType(), True)]
])

# Convert the pandas DataFrame to a Spark DataFrame
df = spark.createDataFrame(df_1)

# Show the first 5 rows of the Spark DataFrame
df.show(5)

# Assemble the features into a vector column
assembler = VectorAssembler(inputCols=[f"feature_{i}" for i in range(57)], outputCol="features_vector")

# Scale the features to have unit variance
scaler = StandardScaler(inputCol="features_vector", outputCol="features", withStd=True, withMean=False)

# Split the data into training (70%) and test (30%) sets
train_data, test_data = df.randomSplit([0.70, 0.3], seed=42)

# Randomly order the training data and show the first 10 rows
from pyspark.sql.functions import rand
train_data.orderBy(rand()).show(10)

# Calculate the prior probabilities for each class (label)
from pyspark.sql.functions import col, when, log, count, mean, stddev

# Step 1: Prepare the data
class_counts = train_data.groupBy('label').count().collect()
total_count = train_data.count()
priors = {row['label']: row['count'] / total_count for row in class_counts}

# Step 2: Calculate mean and standard deviation for each feature, grouped by class
feature_stats = {}
num_features = 57

# For each label (class), compute the mean and stddev for each feature
for label in priors.keys():
    stats = []
    for i in range(num_features):
        mean_col = mean(col(f'feature_{i}'))  # Calculate mean for feature_i
        stddev_col = stddev(col(f'feature_{i}'))  # Calculate stddev for feature_i
        # Filter rows by label and calculate the mean and stddev for feature_i
        group_stats = train_data.filter(col('label') == label).select(mean_col, stddev_col).first()
        stats.append((group_stats[0], group_stats[1]))  # Store mean and stddev for each feature
    feature_stats[label] = stats  # Store the stats for each label

# Step 3: Define a function to predict a label for a given feature set using Naive Bayes
def predict(features):
    log_probs = {}
    for label, class_prior in priors.items():
        log_prob = np.log(class_prior)  # Start with the log of the prior
        for i, feature in enumerate(features):
            mean, std = feature_stats[label][i]
            if std > 0:  # Check to avoid division by zero
                # Apply Gaussian Naive Bayes formula
                log_prob -= 0.5 * np.log(2 * np.pi * std ** 2)
                log_prob -= ((feature - mean) ** 2) / (2 * std ** 2)
        log_probs[label] = log_prob
    return max(log_probs, key=log_probs.get)

# Define a function to apply the Naive Bayes model to each row in the test set
def predict_features(row):
    features = [row[f'feature_{i}'] for i in range(57)]  # Extract features
    prediction = predict(features)  # Predict the label
    return Row(label=row['label'], prediction=prediction)  # Return label and predicted label

# Apply the Naive Bayes model to the test data
test_data_with_predictions = test_data.rdd.map(predict_features).toDF()

# Step 5: Evaluate the model by calculating accuracy
correct_predictions = test_data_with_predictions.filter(col('label') == col('prediction')).count()
total_predictions = test_data_with_predictions.count()
accuracy = correct_predictions / total_predictions
print(f"Custom Naive Bayes Accuracy: {accuracy:.2f}")

# Calculate accuracy again for clarity
correct_predictions = test_data_with_predictions.filter(col('label') == col('prediction')).count()
total_predictions = test_data_with_predictions.count()
accuracy = correct_predictions / total_predictions
print(f"Accuracy: {accuracy:.2f}")

# Show the schema of the resulting DataFrame with predictions
test_data_with_predictions.printSchema()

# Convert the Spark DataFrame to a pandas DataFrame for plotting
pandas_df = test_data_with_predictions.toPandas()

# Import Seaborn for visualization and confusion matrix for evaluation
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

# Calculate confusion matrix using pandas DataFrame
conf_matrix = confusion_matrix(pandas_df['label'], pandas_df['prediction'])

# Plot the confusion matrix using Seaborn
plt.figure(figsize=(10, 7))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

# Create a DataFrame for plotting counts of actual vs. predicted labels
plot_df = pandas_df.groupby(['label', 'prediction']).size().reset_index(name='counts')

# Plot the comparison between actual and predicted labels using Seaborn
plt.figure(figsize=(10, 7))
sns.barplot(x='label', y='counts', hue='prediction', data=plot_df)
plt.title('Comparison of Actual vs. Predicted Classes')
plt.xlabel('Actual Labels')
plt.ylabel('Counts')
plt.legend(title='Predicted Labels')
plt.show()

# Uncomment the following lines to use the built-in PySpark Naive Bayes model
# # Define the Naive Bayes classifier
# nb = NaiveBayes()

# # Set up the pipeline for classification
# pipeline = Pipeline(stages=[assembler, scaler, nb])

# # Train the Naive Bayes model
# model = pipeline.fit(train_data)

# # Make predictions using the trained model
# predictions = model.transform(test_data)
# predictions.select("prediction", "label", "features").show(5)

# # Evaluate the model using the accuracy metric
# evaluator = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="accuracy")
# accuracy = evaluator.evaluate(predictions)
# print(f"Test set accuracy = {accuracy:.2f}")

